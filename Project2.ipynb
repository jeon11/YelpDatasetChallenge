{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = list(open('yelp_dataset/yelp_reviews.json'))\n",
    "json_reviews = [json.loads(rev) for rev in reviews[:50000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = json_reviews[:int(len(json_reviews)*0.25)]\n",
    "train_set = [(rev['text'].lower().replace('\\n', '').split(' '), rev['stars']) for rev in train_set if rev['stars'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_text = []\n",
    "train_neg_text = []\n",
    "\n",
    "train_pos_avg_word_len = []\n",
    "train_pos_avg_rev_len = []\n",
    "\n",
    "train_neg_avg_word_len = []\n",
    "train_neg_avg_rev_len = []\n",
    "\n",
    "for review in train_set:\n",
    "    if review[1] > 3:\n",
    "        train_pos_text.append(review)\n",
    "    elif review[1] < 3:\n",
    "        train_neg_text.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# threshold for positive stop word review length vs negative stop word review length (below positive, above negative)\n",
    "pos_stops = []\n",
    "for review in train_pos_text:\n",
    "    pos_stops.append((len([word for word in review[0] if word in stop]), review[1]))\n",
    "    \n",
    "neg_stops = []\n",
    "for review in train_neg_text:\n",
    "    neg_stops.append((len([word for word in review[0] if word in stop]), review[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of positive words\n",
    "poswords = list(open('poswords.txt', 'r'))\n",
    "poswords = [word.split('\\n')[0] for word in poswords]\n",
    "\n",
    "#list of negative words\n",
    "negwords = list(open('negwords.txt', 'r'))\n",
    "negwords = [word.split('\\n')[0] for word in negwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for each in train_set:\n",
    "    avg_word_len = np.mean([len(word) for word in each[0]])\n",
    "    rev_len = len(each[0])\n",
    "    stop_count = len([word for word in each[0] if word in stop])\n",
    "    pos_word_count = len([word for word in each[0] if word in poswords])\n",
    "    neg_word_count = len([word for word in each[0] if word in negwords])\n",
    "    scores.append([avg_word_len, rev_len, stop_count, pos_word_count, neg_word_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = json_reviews[int(len(json_reviews)*0.25):]\n",
    "test_set = [(rev['text'].lower().replace('\\n', '').split(' '), rev['stars']) for rev in test_set if rev['stars'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess_scores = []\n",
    "for each in test_set:\n",
    "    avg_word_len = np.mean([len(word) for word in each[0]])\n",
    "    rev_len = len(each[0])\n",
    "    stop_count = len([word for word in each[0] if word in stop])\n",
    "    pos_word_count = len([word for word in each[0] if word in poswords])\n",
    "    neg_word_count = len([word for word in each[0] if word in negwords])\n",
    "    guess_scores.append([avg_word_len, rev_len, stop_count, pos_word_count, neg_word_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_train = []\n",
    "for each in train_set:\n",
    "    if each[1] > 3:\n",
    "        log_train.append((each[0], 1))\n",
    "    elif each[1] < 3:\n",
    "        log_train.append((each[0], 0))\n",
    "        \n",
    "log_test = []\n",
    "for each in test_set:\n",
    "    if each[1] > 3:\n",
    "        log_test.append((each[0], 1))\n",
    "    elif each[1] < 3:\n",
    "        log_test.append((each[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(fit_intercept=False, C = 1e9)\n",
    "mdl = model.fit(scores, np.array([e[1] for e in log_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for actual, guess in zip(log_test, guess_scores):\n",
    "    predict = float(mdl.predict(guess))\n",
    "    if actual[1] == predict:\n",
    "        correct +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.45344436033308"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(test_set) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "environment": null,
   "summary": "Cog Sci 190 Project",
   "url": "https://anaconda.org/jkhaykin/project"
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
